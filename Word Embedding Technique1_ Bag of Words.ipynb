{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c804cf-5f8a-4ad7-ade7-eebff8411bd0",
   "metadata": {},
   "source": [
    "# General Word Embeddings\n",
    "\n",
    "**1. Bag of Words (BoW) and TF-IDF**\n",
    "\n",
    "**2. Latent Semantic Analysis (LSA)**\n",
    "\n",
    "**3. Word2Vec developed by Google**\n",
    "\n",
    "**4. GloVe developed by Standford University**\n",
    "\n",
    "**5. FastText developed by FaceBook**\n",
    "\n",
    "**6. Contextual Embeddings**\n",
    "\n",
    "- ELMo : ELMo (Embeddings from Language Models): Developed by Allen Institute for AI\n",
    "\n",
    "- BERT (Bidirectional Encoder Representations from Transformers): Developed by HuggingFace now takeover by Google\n",
    "\n",
    "- GPT (Generative Pre-trained Transformer): Developed by OpenAI\n",
    "\n",
    "**7. Current Trending Models**\n",
    "\n",
    "- GPT-2,GPT-3 and GPT series by OpenAI\n",
    "\n",
    "- BERT Variants: Models like RoBERTa, ALBERT, and DistilBERT have improved upon BERT\n",
    "\n",
    "- T5 (Text-To-Text Transfer Transformer): Developed by Google, T5 treats all NLP tasks as text-to-text problems, unifying multiple tasks under a single framework.\n",
    "\n",
    "- CLIP (Contrastive Language-Image Pretraining): Developed by OpenAI, CLIP learns representations that align images and text, enabling models to perform tasks like zero-shot image classification.\n",
    "\n",
    "- Mistral AI: GenAI model\n",
    "\n",
    "- Google Gemini AI : GenAI model\n",
    "\n",
    "- Amazon Bedrock : GenAI model\n",
    "\n",
    "- llama : Meta AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5ff98-aaa9-43d5-ab55-bd90bb102b43",
   "metadata": {},
   "source": [
    "**1.A Quick Example**\n",
    "    \n",
    "- Let’s look at an easy example to understand the concepts previously explained. We could be interested in analyzing the reviews about Game of Thrones:\n",
    "\n",
    "- **Review 1:** Game of Thrones is an amazing tv series!\n",
    "\n",
    "- **Review 2:** Game of Thrones is the best tv series!\n",
    "\n",
    "- **Review 3:** Game of Thrones is so great\n",
    "\n",
    "In the table, I show all the calculations to obtain the Bag-Of-Words approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1665d-392e-42fd-8a9c-9eb163ad7cc6",
   "metadata": {},
   "source": [
    "**Vocabulary**\n",
    "\n",
    "- Vocabulary means a kind of dictionary\n",
    "\n",
    "- Every data has its own vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a02e75-884d-40e7-9621-0426e57e4ede",
   "metadata": {},
   "source": [
    "**Sentence-1**\n",
    "\n",
    "- sky is nice\n",
    "\n",
    "**Sentence-2**\n",
    "\n",
    "- clouds are nice\n",
    "\n",
    "**Sentence-3**\n",
    "\n",
    "- Sky is nice and Clouds are nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d150aac-f228-4bd2-9c0d-6f2907e6e19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87175e25-7cc8-432f-9f45-9560cd45bd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75f761bc-05a0-407c-aff2-acd5f5f3806d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aadi',\n",
       " 'aaj',\n",
       " 'aap',\n",
       " 'aapne',\n",
       " 'aata',\n",
       " 'aati',\n",
       " 'aaya',\n",
       " 'aaye',\n",
       " 'ab',\n",
       " 'abbe',\n",
       " 'abbey',\n",
       " 'abe',\n",
       " 'abhi',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'accha',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'acha',\n",
       " 'achcha',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agar',\n",
       " 'ain',\n",
       " 'aint',\n",
       " \"ain't\",\n",
       " 'aisa',\n",
       " 'aise',\n",
       " 'aisi',\n",
       " 'alag',\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'andar',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'ap',\n",
       " 'apan',\n",
       " 'apart',\n",
       " 'apna',\n",
       " 'apnaa',\n",
       " 'apne',\n",
       " 'apni',\n",
       " 'appear',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'arent',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'arre',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'at',\n",
       " 'aur',\n",
       " 'avum',\n",
       " 'aya',\n",
       " 'aye',\n",
       " 'baad',\n",
       " 'baar',\n",
       " 'bad',\n",
       " 'bahut',\n",
       " 'bana',\n",
       " 'banae',\n",
       " 'banai',\n",
       " 'banao',\n",
       " 'banaya',\n",
       " 'banaye',\n",
       " 'banayi',\n",
       " 'banda',\n",
       " 'bande',\n",
       " 'bandi',\n",
       " 'bane',\n",
       " 'bani',\n",
       " 'bas',\n",
       " 'bata',\n",
       " 'batao',\n",
       " 'bc',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bhai',\n",
       " 'bheetar',\n",
       " 'bhi',\n",
       " 'bhitar',\n",
       " 'bht',\n",
       " 'bilkul',\n",
       " 'bohot',\n",
       " 'bol',\n",
       " 'bola',\n",
       " 'bole',\n",
       " 'boli',\n",
       " 'bolo',\n",
       " 'bolta',\n",
       " 'bolte',\n",
       " 'bolti',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'bro',\n",
       " 'btw',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " \"can't\",\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chahiye',\n",
       " 'chaiye',\n",
       " 'chal',\n",
       " 'chalega',\n",
       " 'chhaiye',\n",
       " 'clearly',\n",
       " \"c'mon\",\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couldnt',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'de',\n",
       " 'dede',\n",
       " 'dega',\n",
       " 'degi',\n",
       " 'dekh',\n",
       " 'dekha',\n",
       " 'dekhe',\n",
       " 'dekhi',\n",
       " 'dekho',\n",
       " 'denge',\n",
       " 'dhang',\n",
       " 'di',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " \"didn't\",\n",
       " 'dijiye',\n",
       " 'diya',\n",
       " 'diyaa',\n",
       " 'diye',\n",
       " 'diyo',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'done',\n",
       " 'dono',\n",
       " 'dont',\n",
       " \"don't\",\n",
       " 'doosra',\n",
       " 'doosre',\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'dude',\n",
       " 'dunga',\n",
       " 'dungi',\n",
       " 'during',\n",
       " 'dusra',\n",
       " 'dusre',\n",
       " 'dusri',\n",
       " 'dvaara',\n",
       " 'dvara',\n",
       " 'dwaara',\n",
       " 'dwara',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'ek',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'enough',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'far',\n",
       " 'few',\n",
       " 'fifth',\n",
       " 'fir',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'forth',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'gaya',\n",
       " 'gaye',\n",
       " 'gayi',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'ghar',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'haan',\n",
       " 'had',\n",
       " 'hadd',\n",
       " 'hadn',\n",
       " 'hadnt',\n",
       " \"hadn't\",\n",
       " 'hai',\n",
       " 'hain',\n",
       " 'hamara',\n",
       " 'hamare',\n",
       " 'hamari',\n",
       " 'hamne',\n",
       " 'han',\n",
       " 'happens',\n",
       " 'har',\n",
       " 'hardly',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'hasnt',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " 'havent',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " \"here's\",\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hm',\n",
       " 'hmm',\n",
       " 'ho',\n",
       " 'hoga',\n",
       " 'hoge',\n",
       " 'hogi',\n",
       " 'hona',\n",
       " 'honaa',\n",
       " 'hone',\n",
       " 'honge',\n",
       " 'hongi',\n",
       " 'honi',\n",
       " 'hopefully',\n",
       " 'hota',\n",
       " 'hotaa',\n",
       " 'hote',\n",
       " 'hoti',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'hoyenge',\n",
       " 'hoyengi',\n",
       " 'hu',\n",
       " 'hua',\n",
       " 'hue',\n",
       " 'huh',\n",
       " 'hui',\n",
       " 'hum',\n",
       " 'humein',\n",
       " 'humne',\n",
       " 'hun',\n",
       " 'huye',\n",
       " 'huyi',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'idk',\n",
       " 'ie',\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'imo',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'inhe',\n",
       " 'inhi',\n",
       " 'inho',\n",
       " 'inka',\n",
       " 'inkaa',\n",
       " 'inke',\n",
       " 'inki',\n",
       " 'inn',\n",
       " 'inner',\n",
       " 'inse',\n",
       " 'insofar',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " 'ise',\n",
       " 'isi',\n",
       " 'iska',\n",
       " 'iskaa',\n",
       " 'iske',\n",
       " 'iski',\n",
       " 'isme',\n",
       " 'isn',\n",
       " 'isne',\n",
       " 'isnt',\n",
       " \"isn't\",\n",
       " 'iss',\n",
       " 'isse',\n",
       " 'issi',\n",
       " 'isski',\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " 'itna',\n",
       " 'itne',\n",
       " 'itni',\n",
       " 'itno',\n",
       " 'its',\n",
       " \"it's\",\n",
       " 'itself',\n",
       " 'ityaadi',\n",
       " 'ityadi',\n",
       " \"i've\",\n",
       " 'ja',\n",
       " 'jaa',\n",
       " 'jab',\n",
       " 'jabh',\n",
       " 'jaha',\n",
       " 'jahaan',\n",
       " 'jahan',\n",
       " 'jaisa',\n",
       " 'jaise',\n",
       " 'jaisi',\n",
       " 'jata',\n",
       " 'jayega',\n",
       " 'jidhar',\n",
       " 'jin',\n",
       " 'jinhe',\n",
       " 'jinhi',\n",
       " 'jinho',\n",
       " 'jinhone',\n",
       " 'jinka',\n",
       " 'jinke',\n",
       " 'jinki',\n",
       " 'jinn',\n",
       " 'jis',\n",
       " 'jise',\n",
       " 'jiska',\n",
       " 'jiske',\n",
       " 'jiski',\n",
       " 'jisme',\n",
       " 'jiss',\n",
       " 'jisse',\n",
       " 'jitna',\n",
       " 'jitne',\n",
       " 'jitni',\n",
       " 'jo',\n",
       " 'just',\n",
       " 'jyaada',\n",
       " 'jyada',\n",
       " 'k',\n",
       " 'ka',\n",
       " 'kaafi',\n",
       " 'kab',\n",
       " 'kabhi',\n",
       " 'kafi',\n",
       " 'kaha',\n",
       " 'kahaa',\n",
       " 'kahaan',\n",
       " 'kahan',\n",
       " 'kahi',\n",
       " 'kahin',\n",
       " 'kahte',\n",
       " 'kaisa',\n",
       " 'kaise',\n",
       " 'kaisi',\n",
       " 'kal',\n",
       " 'kam',\n",
       " 'kar',\n",
       " 'kara',\n",
       " 'kare',\n",
       " 'karega',\n",
       " 'karegi',\n",
       " 'karen',\n",
       " 'karenge',\n",
       " 'kari',\n",
       " 'karke',\n",
       " 'karna',\n",
       " 'karne',\n",
       " 'karni',\n",
       " 'karo',\n",
       " 'karta',\n",
       " 'karte',\n",
       " 'karti',\n",
       " 'karu',\n",
       " 'karun',\n",
       " 'karunga',\n",
       " 'karungi',\n",
       " 'kaun',\n",
       " 'kaunsa',\n",
       " 'kayi',\n",
       " 'kch',\n",
       " 'ke',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'keh',\n",
       " 'kehte',\n",
       " 'kept',\n",
       " 'khud',\n",
       " 'ki',\n",
       " 'kin',\n",
       " 'kine',\n",
       " 'kinhe',\n",
       " 'kinho',\n",
       " 'kinka',\n",
       " 'kinke',\n",
       " 'kinki',\n",
       " 'kinko',\n",
       " 'kinn',\n",
       " 'kino',\n",
       " 'kis',\n",
       " 'kise',\n",
       " 'kisi',\n",
       " 'kiska',\n",
       " 'kiske',\n",
       " 'kiski',\n",
       " 'kisko',\n",
       " 'kisliye',\n",
       " 'kisne',\n",
       " 'kitna',\n",
       " 'kitne',\n",
       " 'kitni',\n",
       " 'kitno',\n",
       " 'kiya',\n",
       " 'kiye',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'ko',\n",
       " 'koi',\n",
       " 'kon',\n",
       " 'konsa',\n",
       " 'koyi',\n",
       " 'krna',\n",
       " 'krne',\n",
       " 'kuch',\n",
       " 'kuchch',\n",
       " 'kuchh',\n",
       " 'kul',\n",
       " 'kull',\n",
       " 'kya',\n",
       " 'kyaa',\n",
       " 'kyu',\n",
       " 'kyuki',\n",
       " 'kyun',\n",
       " 'kyunki',\n",
       " 'lagta',\n",
       " 'lagte',\n",
       " 'lagti',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'le',\n",
       " 'least',\n",
       " 'lekar',\n",
       " 'lekin',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'li',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'little',\n",
       " 'liya',\n",
       " 'liye',\n",
       " 'll',\n",
       " 'lo',\n",
       " 'log',\n",
       " 'logon',\n",
       " 'lol',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'lunga',\n",
       " 'm',\n",
       " 'maan',\n",
       " 'maana',\n",
       " 'maane',\n",
       " 'maani',\n",
       " 'maano',\n",
       " 'magar',\n",
       " 'mai',\n",
       " 'main',\n",
       " 'maine',\n",
       " 'mainly',\n",
       " 'mana',\n",
       " 'mane',\n",
       " 'mani',\n",
       " 'mano',\n",
       " 'many',\n",
       " 'mat',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meanwhile',\n",
       " 'mein',\n",
       " 'mera',\n",
       " 'mere',\n",
       " 'merely',\n",
       " 'meri',\n",
       " 'might',\n",
       " 'mightn',\n",
       " 'mightnt',\n",
       " \"mightn't\",\n",
       " 'mil',\n",
       " 'mjhe',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'much',\n",
       " 'mujhe',\n",
       " 'must',\n",
       " 'mustn',\n",
       " 'mustnt',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'na',\n",
       " 'naa',\n",
       " 'naah',\n",
       " 'nahi',\n",
       " 'nahin',\n",
       " 'nai',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'ne',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'neeche',\n",
       " 'need',\n",
       " 'needn',\n",
       " 'neednt',\n",
       " \"needn't\",\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nhi',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nope',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'par',\n",
       " 'pata',\n",
       " 'pe',\n",
       " 'pehla',\n",
       " 'pehle',\n",
       " 'pehli',\n",
       " 'people',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'phla',\n",
       " 'phle',\n",
       " 'phli',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'poora',\n",
       " 'poori',\n",
       " 'provides',\n",
       " 'pura',\n",
       " 'puri',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'raha',\n",
       " 'rahaa',\n",
       " 'rahe',\n",
       " 'rahi',\n",
       " 'rakh',\n",
       " 'rakha',\n",
       " 'rakhe',\n",
       " 'rakhen',\n",
       " 'rakhi',\n",
       " 'rakho',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'rehte',\n",
       " 'rha',\n",
       " 'rhaa',\n",
       " 'rhe',\n",
       " 'rhi',\n",
       " 'ri',\n",
       " 'right',\n",
       " 's',\n",
       " 'sa',\n",
       " 'saara',\n",
       " 'saare',\n",
       " 'saath',\n",
       " 'sab',\n",
       " 'sabhi',\n",
       " 'sabse',\n",
       " 'sahi',\n",
       " 'said',\n",
       " 'sakta',\n",
       " 'saktaa',\n",
       " 'sakte',\n",
       " 'sakti',\n",
       " 'same',\n",
       " 'sang',\n",
       " 'sara',\n",
       " 'sath',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'se',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'shan',\n",
       " 'shant',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " 'shouldnt',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'si',\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'soch',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " 'tab',\n",
       " 'tabh',\n",
       " 'tak',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'tarah',\n",
       " 'teen',\n",
       " 'teeno',\n",
       " 'teesra',\n",
       " 'teesre',\n",
       " 'teesri',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'tera',\n",
       " 'tere',\n",
       " 'teri',\n",
       " 'th',\n",
       " 'tha',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'thats',\n",
       " \"that's\",\n",
       " 'the',\n",
       " 'theek',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'theres',\n",
       " \"there's\",\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'thi',\n",
       " 'thik',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'third',\n",
       " 'this',\n",
       " 'tho',\n",
       " 'thoda',\n",
       " 'thodi',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'tjhe',\n",
       " 'to',\n",
       " 'together',\n",
       " 'toh',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'true',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'tu',\n",
       " 'tujhe',\n",
       " 'tum',\n",
       " 'tumhara',\n",
       " 'tumhare',\n",
       " 'tumhari',\n",
       " 'tune',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'um',\n",
       " 'umm',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unhe',\n",
       " 'unhi',\n",
       " 'unho',\n",
       " 'unhone',\n",
       " 'unka',\n",
       " 'unkaa',\n",
       " 'unke',\n",
       " 'unki',\n",
       " 'unko',\n",
       " 'unless',\n",
       " 'unlikely',\n",
       " 'unn',\n",
       " 'unse',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upar',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'usi',\n",
       " 'using',\n",
       " 'uska',\n",
       " 'uske',\n",
       " 'usne',\n",
       " 'uss',\n",
       " 'usse',\n",
       " 'ussi',\n",
       " 'usually',\n",
       " 'vaala',\n",
       " 'vaale',\n",
       " 'vaali',\n",
       " 'vahaan',\n",
       " 'vahan',\n",
       " 'vahi',\n",
       " 'vahin',\n",
       " 'vaisa',\n",
       " 'vaise',\n",
       " 'vaisi',\n",
       " 'vala',\n",
       " 'vale',\n",
       " 'vali',\n",
       " 'various',\n",
       " 've',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vo',\n",
       " 'waala',\n",
       " 'waale',\n",
       " 'waali',\n",
       " 'wagaira',\n",
       " 'wagairah',\n",
       " 'wagerah',\n",
       " 'waha',\n",
       " 'wahaan',\n",
       " 'wahan',\n",
       " 'wahi',\n",
       " 'wahin',\n",
       " 'waisa',\n",
       " 'waise',\n",
       " 'waisi',\n",
       " 'wala',\n",
       " 'wale',\n",
       " 'wali',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'wasnt',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " 'well',\n",
       " \"we'll\",\n",
       " 'went',\n",
       " 'were',\n",
       " \"we're\",\n",
       " 'weren',\n",
       " 'werent',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'whatever',\n",
       " \"what's\",\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " \"where's\",\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " \"who's\",\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'with',\n",
       " 'within',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('hinglish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74007432-0d4c-4425-abef-f9d7a1d7e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sky nice', 'clouds nice', 'sky nice clouds nice']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sentences = ['sky is nice', 'clouds are nice', 'Sky is nice and Clouds are nice']\n",
    "\n",
    "cleaned_sentence = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    word = sentence.lower()  \n",
    "    ##lowering all the letters becaz we dont want it to treat uppercase and lower case words differently\n",
    "    \n",
    "    word = word.split()    ##splitting our sentence into words \n",
    "    \n",
    "    ##removing stop words\n",
    "    word = [i for i in word if i not in set(stopwords.words('english'))]          \n",
    "    word = \" \".join(word)               ##joining our words back to sentences\n",
    "    cleaned_sentence.append(word)       ##appending our preprocessed sentence into a new list\n",
    "    \n",
    "    \n",
    "## printing our new list\n",
    "print(cleaned_sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7744b18-3935-4a1f-94ad-f53b10e7990d",
   "metadata": {},
   "source": [
    "After data preprocess and apply Stop words\n",
    "\n",
    "**Sentence-1**\n",
    "\n",
    "- sky nice\n",
    "\n",
    "**Sentence-2**\n",
    "\n",
    "- clouds nice\n",
    "\n",
    "**Sentence-3**\n",
    "\n",
    "- Sky nice Clouds nice\n",
    "\n",
    "**Vocabulary**\n",
    "\n",
    "   - clouds, nice,sky\n",
    "   \n",
    "\n",
    "|vocabulary|Frequency|\n",
    "|----------------|-----|\n",
    "|clouds|2|\n",
    "|nice|4|\n",
    "|sky|2|\n",
    "\n",
    "\n",
    "and number of voacbulry becomes number of features\n",
    "\n",
    "\n",
    "|sentence|feature1(clouds)|featur2(nice)|feature3(sky)|\n",
    "|--------|-----|---|----|\n",
    "|sky nice|0|1|1|\n",
    "|clouds nice|1|1|0|\n",
    "|Sky nice Clouds nice|1|2|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a43c55df-a2f2-4d37-9b43-d48fce2495f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1],\n",
       "       [1, 1, 0],\n",
       "       [1, 2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 3)  ##give it a max features as 3\n",
    "Bagofwords = cv.fit_transform(cleaned_sentence)\n",
    "\n",
    "#Bagofwords.toarray()\n",
    "Bagofwords\n",
    "Bagofwords.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bc04975-d002-45ac-8f14-6beddc1c68e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_request_for_signature',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_validate_data',\n",
       " '_validate_ngram_range',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names_out',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'preprocessor',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_transform_request',\n",
       " 'stop_words',\n",
       " 'strip_accents',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "656ae0b8-b8f7-4034-bb5f-7a31ce1a594f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cloud</th>\n",
       "      <th>nice</th>\n",
       "      <th>sky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cloud  nice  sky\n",
       "0      0     1    1\n",
       "1      1     1    0\n",
       "2      1     2    1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(Bagofwords.toarray(),columns=['cloud','nice','sky'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "987c2cc3-6092-45d4-b743-9e1e4be73a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sky': 2, 'nice': 1, 'clouds': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_\n",
    "# unique words with index\n",
    "# cloud is first word : first feature\n",
    "# nice is scond word: second feature\n",
    "# skt is third word: Third feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0322309-3d89-4401-8735-b67dce6aa2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['game thrones amazing tv series!', 'game thrones best tv series!', 'game thrones great']\n",
      "{'game': 2, 'thrones': 5, 'amazing': 0, 'tv': 6, 'series': 4, 'best': 1, 'great': 3}\n",
      "[[1 0 1 0 1 1 1]\n",
      " [0 1 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "### All together\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = ['Game of Thrones is an amazing tv series!', \n",
    "             'Game of Thrones is the best tv series!', \n",
    "             'Game of Thrones is so great']\n",
    "\n",
    "cleaned_sentence = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    word = sentence.lower()  \n",
    "    ##lowering all the letters becaz we dont want it to treat uppercase and lower case words differently\n",
    "    \n",
    "    word = word.split()    ##splitting our sentence into words \n",
    "    \n",
    "    ##removing stop words\n",
    "    word = [i for i in word if i not in set(stopwords.words('english'))]          \n",
    "    word = \" \".join(word)               ##joining our words back to sentences\n",
    "    cleaned_sentence.append(word)       ##appending our preprocessed sentence into a new list\n",
    "    \n",
    "    \n",
    "## printing our new list\n",
    "print(cleaned_sentence) \n",
    "\n",
    "cv = CountVectorizer()  ##give it a max features as 3\n",
    "Bagofwords = cv.fit_transform(cleaned_sentence).toarray()\n",
    "print(cv.vocabulary_)\n",
    "print(Bagofwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88b8b522-07c0-44ac-a978-603e27f07689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game': 2,\n",
       " 'thrones': 5,\n",
       " 'amazing': 0,\n",
       " 'tv': 6,\n",
       " 'series': 4,\n",
       " 'best': 1,\n",
       " 'great': 3}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_\n",
    "# Index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d13afc2-15cf-4b60-935c-3c50b6ff7212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sky nice', 'clouds nice', 'sky nice clouds nice']\n",
      "{'sky': 4, 'nice': 2, 'sky nice': 5, 'clouds': 0, 'clouds nice': 1, 'nice clouds': 3}\n",
      "[[0 0 1 0 1 1]\n",
      " [1 1 1 0 0 0]\n",
      " [1 1 2 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "### All together\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = ['sky is nice', 'clouds are nice', 'Sky is nice and Clouds are nice']\n",
    "\n",
    "cleaned_sentence = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    word = sentence.lower()  \n",
    "    ##lowering all the letters becaz we dont want it to treat uppercase and lower case words differently\n",
    "    \n",
    "    word = word.split()    ##splitting our sentence into words \n",
    "    \n",
    "    ##removing stop words\n",
    "    word = [i for i in word if i not in set(stopwords.words('english'))]          \n",
    "    word = \" \".join(word)               ##joining our words back to sentences\n",
    "    cleaned_sentence.append(word)       ##appending our preprocessed sentence into a new list\n",
    "    \n",
    "    \n",
    "## printing our new list\n",
    "print(cleaned_sentence) \n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,2))  ##give it a max features as 3\n",
    "Bagofwords = cv.fit_transform(cleaned_sentence).toarray()\n",
    "\n",
    "print(cv.vocabulary_)\n",
    "print(Bagofwords)\n",
    "\n",
    "# Task for you is:  Identify the output logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44aeb77a-c5b2-4c40-ae8b-e14250c4679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clouds', 'clouds nice', 'nice', 'nice clouds', 'sky', 'sky nice']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(cv.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1ef3b1e-c54b-44db-bfec-4ddd887a82ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sky': 4,\n",
       " 'nice': 2,\n",
       " 'sky nice': 5,\n",
       " 'clouds': 0,\n",
       " 'clouds nice': 1,\n",
       " 'nice clouds': 3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_\n",
    "# Vector formation happens based on vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8149d1a5-cbd8-4d8f-aa3e-550cc25d88e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary: ['nice', 'clouds', 'sky']\n",
      "[{'clouds': 0, 'nice': 1, 'sky': 1}, {'clouds': 1, 'nice': 1, 'sky': 0}, {'clouds': 1, 'nice': 1, 'sky': 1}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[dict_values([0, 1, 1]), dict_values([1, 1, 0]), dict_values([1, 1, 1])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################ With logic##################################\n",
    "sen=' '.join(cleaned_sentence)\n",
    "l=list(set(sen.split()))\n",
    "print(\"vocabulary:\",l)\n",
    "d={}\n",
    "l1=[]\n",
    "for sentence in cleaned_sentence:\n",
    "    for i in l:\n",
    "        if i in sentence:\n",
    "            d[i]=1\n",
    "        else:\n",
    "            d[i]=0\n",
    "    myKeys = list(d.keys())\n",
    "    myKeys.sort()\n",
    "    sorted_dict = {i: d[i] for i in myKeys}\n",
    "    l1.append(sorted_dict)\n",
    "\n",
    "print(l1)\n",
    "l2=[i.values() for i in l1]\n",
    "l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcebe2f5-7940-4e56-8489-94fa3939da2d",
   "metadata": {},
   "source": [
    "**Some disadvantages of BOWS:**\n",
    "\n",
    "- It won’t provide any semantic information about the words. It only gives how many times has word occurred in a sentence and not its location or correlation with other words in the sentence.\n",
    "\n",
    "- It gives equal importance to all the words in the sentence. Hence it is most useful for simple processes.\n",
    "\n",
    "- There are other methods like Tfidf, word2Vec which are more complex and useful than BOWs.\n",
    "\n",
    "- BOW\n",
    "\n",
    "- tf-idf\n",
    "\n",
    "- word2vec\n",
    "\n",
    "- Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af3adc60-0324-49b0-957d-5a5e6cd624a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sky': 1, 'is': 2, 'nice': 4, 'clouds': 1, 'are': 2, 'Sky': 1, 'and': 1, 'Clouds': 1}\n"
     ]
    }
   ],
   "source": [
    "# Creating word histogram\n",
    "import nltk\n",
    "word2count = {}\n",
    "for data in sentences:\n",
    "    words = nltk.word_tokenize(data) # we are split into words\n",
    "    for word in words:               # we are calling each word\n",
    "        if word not in word2count.keys(): # if the word not in dictionary, we are \n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "print(word2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdb722-60af-4ed2-b60e-94ff39b589d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
