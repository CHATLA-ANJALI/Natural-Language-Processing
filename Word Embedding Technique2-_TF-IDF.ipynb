{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7121a72e-392f-43e3-b8f9-3b84ffc929e6",
   "metadata": {},
   "source": [
    "- Term Frequency Inverse Document Frequency (TFIDF) analysis is one of the simple and robust methods to understand the context of a text.\n",
    "\n",
    "- Term Frequency and Inverse Document Frequency is used to find the related content and important words and phrases in a larger text. Implementing TF-IDF analysis is very easy using Python.\n",
    "\n",
    "- Computers cannot understand the meaning of a text, but they can understand numbers. The words can be converted to numbers so that the relationship between them can be understood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643deb1-a2d4-499e-99fb-ef86bff9fff2",
   "metadata": {},
   "source": [
    "**Term Frequency:**\n",
    "\n",
    "- The term frequency measure of a word w in a document (text) d.\n",
    "\n",
    "- It is equal to the number of instances of word w in document d divided by the total number of words in document d.\n",
    "\n",
    "- Term frequency serves as a metric to determine a word’s occurrence in a document as compared to the total number of words in a document. The denominator is always the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d160e2bb-13e1-44ec-bd26-2fdfd7f20db9",
   "metadata": {},
   "source": [
    "<img decoding=\"async\" loading=\"lazy\" class=\"alignnone\" src=\"https://editor.analyticsvidhya.com/uploads/27405Screenshot_1.jpg\" alt=\"term frequency | Reviews Classifier Using TF-IDF\" width=\"773\" height=\"102\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a64394-b53b-4cdf-bca7-88108710317c",
   "metadata": {},
   "source": [
    "**Inverse Document Frequency (IDF)**\n",
    "\n",
    "- This parameter gives a numeric value of the importance of a word.\n",
    "\n",
    "- Inverse Document frequency of word w is defined as the total number of documents (N) in a text corpus D, divided by the number of documents containing w."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0afbfa-8ef9-44bd-aae4-046b079dc6dc",
   "metadata": {},
   "source": [
    "<img decoding=\"async\" loading=\"lazy\" class=\"alignnone\" src=\"https://editor.analyticsvidhya.com/uploads/80300Screenshot_2.jpg\" alt=\"Inverse document frequency\" width=\"760\" height=\"86\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00899455-b648-4fe6-9c33-fb6473357cbb",
   "metadata": {},
   "source": [
    "- The product of TF and IDF is the TF-IDF. TF-IDF is usually one of the best metrics to determine if a term is significant to a text. It represents the importance of a word in a particular document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e9bfd-288b-471f-a8cd-c3cf5f73dd91",
   "metadata": {},
   "source": [
    "**Term Frequency**\n",
    "\n",
    "**Sentence-1**\n",
    "\n",
    "- good movie\n",
    "\n",
    "**Sentence-2**\n",
    "\n",
    "- good snacks\n",
    "\n",
    "**Sentence-3**\n",
    "\n",
    "- movie snacks good\n",
    "\n",
    "\n",
    "|vocab|Sentence-1|Sentence-2|Sentence-3|\n",
    "|--------|-----|---|----|\n",
    "|good|1/2|1/2|1/3|\n",
    "|movie|1/2|0/2|1/3|\n",
    "|snacks|0/2|1/2|1/3|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb10b0e-ff3e-425a-8bd8-a8d152103f31",
   "metadata": {},
   "source": [
    "**Inverse document frequency**\n",
    "\n",
    "\n",
    "|vocab|Idf|\n",
    "|-----|---|\n",
    "|good|loge(3/3)|\n",
    "|movie|loge(3/2)|\n",
    "|snacks|loge(3/2)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b59037-9ca5-4066-9bab-4d8bb9e65b82",
   "metadata": {},
   "source": [
    "**Term Frequency** * **Inverse document frequency**\n",
    "\n",
    "\n",
    "\n",
    "|Sentence|good|movie|Snacks|\n",
    "|--------|-----|---|----|\n",
    "|Sentence-1|1/2*0=0|1/2*loge(3/2)|0|\n",
    "|Sentence-2|1/2*0=0|0|1/2*loge(3/2)|\n",
    "|Sentence-3|1/3*0=0|1/3*loge(3/2)|1/3*loge(3/2)|\n",
    "\n",
    "\n",
    "|Sentence|good|movie|Snacks|\n",
    "|--------|-----|---|----|\n",
    "|Sentence-1|0|1/2*loge(3/2)|0|\n",
    "|Sentence-2|0|0|1/2*loge(3/2)|\n",
    "|Sentence-3|0|1/3*loge(3/2)|1/3*loge(3/2)|\n",
    "\n",
    "\n",
    "\n",
    "> good is present in every sentence so the value becomes zero: less importance\n",
    "\n",
    "> movie is present in only two sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65872e3b-5dab-4a74-9afa-be5b5059291f",
   "metadata": {},
   "source": [
    "Let’s cover an example of 3 documents -\n",
    "\n",
    "Document 1            It is going to rain today.\n",
    "\n",
    "Document 2            Today I am not going outside.\n",
    "\n",
    "Document 3            I am going to watch the season premiere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bc92411-290c-4520-96b8-c8ebf913980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=\"It is going to rain today\"\n",
    "d2=\"Today I am not going outside\"\n",
    "d3=\"I am going to watch the season premiere\"\n",
    "\n",
    "l1=d1.split()\n",
    "l2=d2.split()\n",
    "l3=d3.split()\n",
    "val1=set(l1+l2+l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ef31410-ab06-4d3b-865f-a9dfe7982c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 0.17,\n",
       " 'today': 0.17,\n",
       " 'am': 0,\n",
       " 'outside': 0,\n",
       " 'Today': 0,\n",
       " 'rain': 0.17,\n",
       " 'the': 0,\n",
       " 'going': 0.17,\n",
       " 'It': 0.17,\n",
       " 'premiere': 0,\n",
       " 'season': 0,\n",
       " 'watch': 0,\n",
       " 'is': 0.17,\n",
       " 'not': 0,\n",
       " 'I': 0.17}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1={}\n",
    "for i in val1:\n",
    "    if i in d1:\n",
    "        dict1[i]=round(1/len(l1),2)\n",
    "    else:\n",
    "        dict1[i]=0\n",
    "        \n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69c0db88-a7be-4442-95af-2018a5c588e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 0.17,\n",
       " 'today': 0.17,\n",
       " 'am': 0,\n",
       " 'outside': 0,\n",
       " 'Today': 0,\n",
       " 'rain': 0.17,\n",
       " 'the': 0,\n",
       " 'going': 0.17,\n",
       " 'It': 0.17,\n",
       " 'premiere': 0,\n",
       " 'season': 0,\n",
       " 'watch': 0,\n",
       " 'is': 0.17,\n",
       " 'not': 0,\n",
       " 'I': 0.17}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict2={}\n",
    "for i in val1:\n",
    "    if i in d1:\n",
    "        dict2[i]=round(1/len(l2),2)\n",
    "    else:\n",
    "        dict2[i]=0\n",
    "        \n",
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "182d7807-494c-492e-9118-7fc2e2d8aacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 0.12,\n",
       " 'today': 0.12,\n",
       " 'am': 0,\n",
       " 'outside': 0,\n",
       " 'Today': 0,\n",
       " 'rain': 0.12,\n",
       " 'the': 0,\n",
       " 'going': 0.12,\n",
       " 'It': 0.12,\n",
       " 'premiere': 0,\n",
       " 'season': 0,\n",
       " 'watch': 0,\n",
       " 'is': 0.12,\n",
       " 'not': 0,\n",
       " 'I': 0.12}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict3={}\n",
    "for i in val1:\n",
    "    if i in d1:\n",
    "        dict3[i]=round(1/len(l3),2)\n",
    "    else:\n",
    "        dict3[i]=0\n",
    "        \n",
    "dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52104192-098f-48ca-b4df-9a43e7232221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.DataFrame(dict1,index=['A'])\n",
    "df2=pd.DataFrame(dict2,index=['B'])\n",
    "df3=pd.DataFrame(dict3,index=['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e5a44f4-7b82-4e15-9bd3-202040281526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4054651081081644"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.log(3/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414d136-3392-4062-b4de-5c051add5b82",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0cb0e88-bcca-41dc-bf1c-778eb10a0caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['going rain today.', 'Today going outside.', 'going watch season premiere.']\n"
     ]
    }
   ],
   "source": [
    "Document1= \"going rain today.\"\n",
    "Document2= \"Today going outside.\"\n",
    "Document3= \"going watch season premiere.\"\n",
    "Doc = [Document1 ,Document2 , Document3]\n",
    "print(Doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a451074c-b533-4705-a6a0-2cae63aec79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x7 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(Doc)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56220a1e-6b7a-4085-a65a-60b4cc0b5f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'going': 0,\n",
       " 'rain': 3,\n",
       " 'today': 5,\n",
       " 'outside': 1,\n",
       " 'watch': 6,\n",
       " 'season': 4,\n",
       " 'premiere': 2}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_ # index order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62db7b53-9d89-4163-a530-f5125f5afbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42544054, 0.        , 0.        , 0.72033345, 0.        ,\n",
       "        0.54783215, 0.        ],\n",
       "       [0.42544054, 0.72033345, 0.        , 0.        , 0.        ,\n",
       "        0.54783215, 0.        ],\n",
       "       [0.32274454, 0.        , 0.54645401, 0.        , 0.54645401,\n",
       "        0.        , 0.54645401]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54e87029-e915-4c93-a742-2b53d7031e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 ['going', 'rain', 'today']\n",
      "Document 2 ['today', 'going', 'outside']\n",
      "Document 3 ['going', 'watch', 'season', 'premiere']\n",
      "Document transform [[0.42544054 0.         0.         0.72033345 0.         0.54783215\n",
      "  0.        ]\n",
      " [0.42544054 0.72033345 0.         0.         0.         0.54783215\n",
      "  0.        ]\n",
      " [0.32274454 0.         0.54645401 0.         0.54645401 0.\n",
      "  0.54645401]]\n"
     ]
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "print(\"Document 1\",analyze(Document1)) # Individual tf-idf\n",
    "print(\"Document 2\",analyze(Document2))\n",
    "print(\"Document 3\",analyze(Document3))\n",
    "print(\"Document transform\",X.toarray()) # all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7290168a-84fb-4e3c-aef9-71ab0b451ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['going', 'outside', 'premiere', 'rain', 'season', 'today', 'watch'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()  # sorted order of vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a811588-c633-47f7-9a41-272957850786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>going</th>\n",
       "      <th>outside</th>\n",
       "      <th>premiere</th>\n",
       "      <th>rain</th>\n",
       "      <th>season</th>\n",
       "      <th>today</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>going rain today.</th>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today going outside.</th>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>going watch season premiere.</th>\n",
       "      <td>0.322745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 going   outside  premiere      rain  \\\n",
       "going rain today.             0.425441  0.000000  0.000000  0.720333   \n",
       "Today going outside.          0.425441  0.720333  0.000000  0.000000   \n",
       "going watch season premiere.  0.322745  0.000000  0.546454  0.000000   \n",
       "\n",
       "                                season     today     watch  \n",
       "going rain today.             0.000000  0.547832  0.000000  \n",
       "Today going outside.          0.000000  0.547832  0.000000  \n",
       "going watch season premiere.  0.546454  0.000000  0.546454  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X.toarray(),\n",
    "             index=Doc,\n",
    "             columns=[vectorizer.get_feature_names_out()],\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf90104-e521-4e4b-ab1e-6e97c52cc74e",
   "metadata": {},
   "source": [
    "- The output signifies the important words which add context to 3 sentences. These are the words that are important in all 3 sentences and now you can ask questions of whatever nature you like to the machine, stuff like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdbc4bea-1c04-4fe9-9595-3791bcf4b36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b9809ae-c597-4200-9b2e-4b19c5744f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42544054, 0.        , 0.        , 0.72033345, 0.        ,\n",
       "       0.54783215, 0.        ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e0cf76d-5113-4edf-a22b-9b9339630007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good movie.', 'good snacks.', 'movie snacks good.']\n",
      "Document 1 ['good', 'movie']\n",
      "Document 2 ['good', 'snacks']\n",
      "Document 3 ['movie', 'snacks', 'good']\n",
      "Document transform [[1.         1.28768207 0.        ]\n",
      " [1.         0.         1.28768207]\n",
      " [1.         1.28768207 1.28768207]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['good', 'movie', 'snacks'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With out Normalization\n",
    "Document1= \"good movie.\"\n",
    "Document2= \"good snacks.\"\n",
    "Document3= \"movie snacks good.\"\n",
    "Doc = [Document1 ,Document2 , Document3]\n",
    "print(Doc)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "X = vectorizer.fit_transform(Doc)\n",
    "\n",
    "analyze = vectorizer.build_analyzer()\n",
    "print(\"Document 1\",analyze(Document1))\n",
    "print(\"Document 2\",analyze(Document2))\n",
    "print(\"Document 3\",analyze(Document3))\n",
    "print(\"Document transform\",X.toarray())\n",
    "\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45996d7d-976d-476a-b69d-423fd824cc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000025623583"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "v1=[0.61335554, 0.78980693, 0]\n",
    "np.linalg.norm(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1c7cd-d667-4956-bf82-91a9f7a4eb3b",
   "metadata": {},
   "source": [
    "|Sentence|good|movie|Snacks|\n",
    "|--------|-----|---|----|\n",
    "|Sentence-1|1/2*0=0|1/2*loge(3/2)|0|\n",
    "|Sentence-2|1/2*0=0|0|1/2*loge(3/2)|\n",
    "|Sentence-3|1/3*0=0|1/3*loge(3/2)|1/3*loge(3/2)|\n",
    "\n",
    "\n",
    "|Sentence|good|movie|Snacks|\n",
    "|--------|-----|---|----|\n",
    "|Sentence-1|0|1/2*loge(3/2)|0|\n",
    "|Sentence-2|0|0|1/2*loge(3/2)|\n",
    "|Sentence-3|0|1/3*loge(3/2)|1/3*loge(3/2)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2dd3e-8cf5-40d6-ba45-b733813be2f3",
   "metadata": {},
   "source": [
    "(count_of_term_t_in_d) * ((log ((NUMBER_OF_DOCUMENTS + 1) / (Number_of_documents_where_t_appears +1 )) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fbfe5a3-636e-4bcf-8f50-4649b2ea2c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "1 * (np.log((3 + 1)/(3+1)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0c1fe00-4047-4bd3-b967-8f4c1eff816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2876820724517808"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Movie\n",
    "1 * (np.log((3 + 1)/(2+1)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1019172f-3650-4dbd-a6ff-87c23f8d74e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good movie.', 'good snacks.', 'movie snacks good.']\n",
      "Document 1 ['good', 'movie']\n",
      "Document 2 ['good', 'snacks']\n",
      "Document 3 ['movie', 'snacks', 'good']\n",
      "Document transform [[0.61335554 0.78980693 0.        ]\n",
      " [0.61335554 0.         0.78980693]\n",
      " [0.48133417 0.61980538 0.61980538]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['good', 'movie', 'snacks'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Normalization\n",
    "Document1= \"good movie.\"\n",
    "Document2= \"good snacks.\"\n",
    "Document3= \"movie snacks good.\"\n",
    "Doc = [Document1 ,Document2 , Document3]\n",
    "print(Doc)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(Doc)\n",
    "\n",
    "analyze = vectorizer.build_analyzer()\n",
    "print(\"Document 1\",analyze(Document1))\n",
    "print(\"Document 2\",analyze(Document2))\n",
    "print(\"Document 3\",analyze(Document3))\n",
    "print(\"Document transform\",X.toarray())\n",
    "\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04d25b50-535c-4124-989f-7228c9b6b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61335554 0.78980693 0.        ]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vector = [1, 1.28768207, 0 ]\n",
    "\n",
    "tfidf_vector = tfidf_vector / np.linalg.norm(tfidf_vector)\n",
    "\n",
    "print(tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c39fb-6cf7-4743-8032-745154e2d1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
